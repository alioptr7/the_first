"""update models

Revision ID: f8744a559a2b
Revises: 53f556dd6c32
Create Date: 2025-10-28 05:45:58.854177

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'f8744a559a2b'
down_revision: Union[str, None] = '53f556dd6c32'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_export_batches_batch_type'), table_name='export_batches')
    op.drop_index(op.f('ix_export_batches_checksum'), table_name='export_batches')
    op.drop_index(op.f('ix_export_batches_status'), table_name='export_batches')
    op.drop_table('export_batches')
    op.drop_index(op.f('ix_system_logs_component'), table_name='system_logs')
    op.drop_index(op.f('ix_system_logs_level'), table_name='system_logs')
    op.drop_index(op.f('ix_system_logs_request_id'), table_name='system_logs')
    op.drop_table('system_logs')
    op.drop_index(op.f('ix_import_batches_batch_type'), table_name='import_batches')
    op.drop_index(op.f('ix_import_batches_checksum'), table_name='import_batches')
    op.drop_index(op.f('ix_import_batches_status'), table_name='import_batches')
    op.drop_table('import_batches')
    op.drop_index(op.f('ix_query_results_export_batch_id'), table_name='query_results')
    op.drop_index(op.f('ix_query_results_original_request_id'), table_name='query_results')
    op.drop_index(op.f('ix_query_results_request_id'), table_name='query_results')
    op.drop_table('query_results')
    op.drop_index(op.f('ix_incoming_requests_import_batch_id'), table_name='incoming_requests')
    op.drop_index(op.f('ix_incoming_requests_original_request_id'), table_name='incoming_requests')
    op.drop_index(op.f('ix_incoming_requests_status'), table_name='incoming_requests')
    op.drop_table('incoming_requests')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('incoming_requests',
    sa.Column('original_request_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('query_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('query_params', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('priority', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('elasticsearch_query', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('imported_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('import_batch_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('assigned_worker', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('started_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('retry_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('meta', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='incoming_requests_pkey'),
    postgresql_ignore_search_path=False
    )
    op.create_index(op.f('ix_incoming_requests_status'), 'incoming_requests', ['status'], unique=False)
    op.create_index(op.f('ix_incoming_requests_original_request_id'), 'incoming_requests', ['original_request_id'], unique=True)
    op.create_index(op.f('ix_incoming_requests_import_batch_id'), 'incoming_requests', ['import_batch_id'], unique=False)
    op.create_table('query_results',
    sa.Column('original_request_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('result_data', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('execution_time_ms', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('cache_hit', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('exported_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('export_batch_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('request_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('result_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('elasticsearch_took_ms', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('executed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('meta', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['request_id'], ['incoming_requests.id'], name=op.f('query_results_request_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('query_results_pkey'))
    )
    op.create_index(op.f('ix_query_results_request_id'), 'query_results', ['request_id'], unique=True)
    op.create_index(op.f('ix_query_results_original_request_id'), 'query_results', ['original_request_id'], unique=False)
    op.create_index(op.f('ix_query_results_export_batch_id'), 'query_results', ['export_batch_id'], unique=False)
    op.create_table('import_batches',
    sa.Column('processed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('batch_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('filename', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('file_path', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('file_size_bytes', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('record_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('checksum', sa.VARCHAR(length=64), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('meta', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('import_batches_pkey')),
    sa.UniqueConstraint('filename', name=op.f('import_batches_filename_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_index(op.f('ix_import_batches_status'), 'import_batches', ['status'], unique=False)
    op.create_index(op.f('ix_import_batches_checksum'), 'import_batches', ['checksum'], unique=False)
    op.create_index(op.f('ix_import_batches_batch_type'), 'import_batches', ['batch_type'], unique=False)
    op.create_table('system_logs',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('level', sa.VARCHAR(length=20), autoincrement=False, nullable=False),
    sa.Column('component', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('message', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('error_trace', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('request_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('meta', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('system_logs_pkey'))
    )
    op.create_index(op.f('ix_system_logs_request_id'), 'system_logs', ['request_id'], unique=False)
    op.create_index(op.f('ix_system_logs_level'), 'system_logs', ['level'], unique=False)
    op.create_index(op.f('ix_system_logs_component'), 'system_logs', ['component'], unique=False)
    op.create_table('export_batches',
    sa.Column('processed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('batch_type', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('filename', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('file_path', sa.VARCHAR(length=500), autoincrement=False, nullable=False),
    sa.Column('file_size_bytes', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('record_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('checksum', sa.VARCHAR(length=64), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('meta', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name=op.f('export_batches_pkey')),
    sa.UniqueConstraint('filename', name=op.f('export_batches_filename_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_index(op.f('ix_export_batches_status'), 'export_batches', ['status'], unique=False)
    op.create_index(op.f('ix_export_batches_checksum'), 'export_batches', ['checksum'], unique=False)
    op.create_index(op.f('ix_export_batches_batch_type'), 'export_batches', ['batch_type'], unique=False)
    # ### end Alembic commands ###