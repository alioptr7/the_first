# ğŸ“‹ ÙØ±Ø§ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ Celery + Unicorn + Redis

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡
Ø³ÛŒØ³ØªÙ… Ø§Ø² **3 Ú©Ø§Ù…Ù¾ÙˆÙ†Ù†Øª Ø§ØµÙ„ÛŒ** ØªØ´Ú©ÛŒÙ„ Ø´Ø¯Ù‡:
1. **Unicorn API** - ÙˆØ¨ Ø³Ø±ÙˆØ± (Fastapi)
2. **Celery Beat** - Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ² (Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ)
3. **Celery Worker** - Ø§Ø¬Ø±Ø§Ú¯Ø± (Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÚ¯Ø±)

ØªÙ…Ø§Ù… Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ø² Ø·Ø±ÛŒÙ‚ **Redis** Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.

---

## ğŸš€ Ù…Ø±Ø§Ø­Ù„ Ø´Ø±ÙˆØ¹ (Ø¯Ø± Windows)

### 1ï¸âƒ£ Redis Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯
```bash
# Ø§Ú¯Ø± Docker Ù†ÛŒØ³Øª
redis-server --port 6380
```

### 2ï¸âƒ£ Unicorn API Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯
```bash
# Ø¯Ø± Terminal 1
cd response-network/api
uvicorn main:app --host 127.0.0.1 --port 8000 --reload

# Output:
# INFO:     Started server process [1234]
# INFO:     Uvicorn running on http://127.0.0.1:8000
```

### 3ï¸âƒ£ Celery Beat Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯
```bash
# Ø¯Ø± Terminal 2
cd response-network/api
python -m celery -A workers.celery_app beat --loglevel=info

# Output:
# celery beat v5.3.0 (sun)
# [*] Scheduler: celery.beat.PersistentScheduler
# [*] Synchronizing schedule
# [*] Schedule entry 'export-settings-every-minute': export_settings_to_request_network 60.00s
```

### 4ï¸âƒ£ Celery Worker Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯
```bash
# Ø¯Ø± Terminal 3
cd response-network/api
python -m celery -A workers.celery_app worker --pool=solo --loglevel=info

# Output:
# celery@DESKTOP-XXXX ready. [*] celery@DESKTOP-XXXX ready. [*] ...
# [*] pool: solo
# [*] concurrency: 1
```

---

## ğŸ“ Ù…Ø¹Ù…Ø§Ø±ÛŒ ÙÛŒØ²ÛŒÚ©ÛŒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                           â”‚
â”‚  Windows Machine (127.0.0.1)                            â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Unicorn API   â”‚  â”‚ Celery Beat    â”‚  â”‚  Worker   â”‚ â”‚
â”‚  â”‚  :8000         â”‚  â”‚  (Scheduler)   â”‚  â”‚ (Executor)â”‚ â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚           â”‚ â”‚
â”‚  â”‚ FastAPI        â”‚  â”‚ Timer-based    â”‚  â”‚ Process   â”‚ â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚ Tasks     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â–²                   â”‚                     â–²       â”‚
â”‚        â”‚                   â”‚                     â”‚       â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                            â”‚ (Queue / Commands)          â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚        â”‚      Redis (localhost:6380)              â”‚     â”‚
â”‚        â”‚                                          â”‚     â”‚
â”‚        â”‚  Queue: celery                          â”‚     â”‚
â”‚        â”‚  â”œâ”€ Task 1: export_settings             â”‚     â”‚
â”‚        â”‚  â”œâ”€ Task 2: export_users                â”‚     â”‚
â”‚        â”‚  â””â”€ Task 3: settings_importer           â”‚     â”‚
â”‚        â”‚                                          â”‚     â”‚
â”‚        â”‚  Backend: Result Storage                 â”‚     â”‚
â”‚        â”‚  â”œâ”€ task_id_1: "success"                â”‚     â”‚
â”‚        â”‚  â””â”€ task_id_2: "failed"                 â”‚     â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                           â”‚
â”‚  File System:                                           â”‚
â”‚  â””â”€ response-network/exports/                          â”‚
â”‚     â”œâ”€ settings/settings_latest.json                   â”‚
â”‚     â”œâ”€ users/users_queue.json                          â”‚
â”‚     â””â”€ password_changes/password_changes_queue.json    â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ ÙØ±Ø§ÛŒÙ†Ø¯ Ú©Ø§Ù…Ù„ (Ù…Ø«Ø§Ù„: export_settings)

### ğŸ“ Ù…Ø±Ø­Ù„Ù‡ 1: ØªØ¹Ø±ÛŒÙ Task
**ÙØ§ÛŒÙ„:** `response-network/api/workers/tasks/settings_exporter.py`

```python
from celery import shared_task

@shared_task(bind=True, max_retries=3)
def export_settings_to_request_network(self):
    """
    Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ settings_latest.json Ùˆ settings_queue.json
    """
    # 1. Ø§ØªØµØ§Ù„ Ø¨Ù‡ Database
    db = next(get_db_sync())
    
    # 2. Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… settings
    settings = db.query(SettingsModel).all()
    
    # 3. Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
    EXPORT_PATH.mkdir(parents=True, exist_ok=True)
    with open(EXPORT_PATH / "settings_latest.json", "w") as f:
        json.dump([...], f)
    
    # 4. Ù†ØªÛŒØ¬Ù‡ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†
    return {"status": "success", "count": len(settings)}
```

**Ú©Ù„ÛŒØ¯ Ù…Ù‡Ù…:** `@shared_task` = Celery Ù…ÛŒØªÙˆØ§Ù†Ø¯ Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø±Ø§ ØµÙâ€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù†Ø¯

---

### â° Ù…Ø±Ø­Ù„Ù‡ 2: Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ²Ù…Ø§Ù†ÛŒ (Beat)
**ÙØ§ÛŒÙ„:** `response-network/api/workers/celery_app.py`

```python
celery_app.conf.beat_schedule = {
    "export-settings-every-minute": {
        "task": "workers.tasks.settings_exporter.export_settings_to_request_network",
        "schedule": 60.0,  # Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡
    },
}
```

**Ù…Ø¹Ù†ÛŒ:**
- **Task:** Ù†Ø§Ù… ØªØ³Ú© Ú©Ø§Ù…Ù„ (Ù…Ø³ÛŒØ± Ù…Ø§Ú˜ÙˆÙ„ + Ù†Ø§Ù… ØªØ§Ø¨Ø¹)
- **Schedule:** Ù‡Ø± Ú†Ù†Ø¯ Ø«Ø§Ù†ÛŒÙ‡

---

### â±ï¸ Ù…Ø±Ø­Ù„Ù‡ 3: Beat Ù…Ù†ØªØ¸Ø± Ø§Ø³Øª

**Ø²Ù…Ø§Ù†: 14:30:00**

Beat Ø¯Ø± Ø­Ø§Ù„ Ù†Ø¸Ø§Ø±Øª Ø§Ø³Øª:
```
Beat Scheduler (Running...)
â”œâ”€ Current Time: 14:30:00
â”œâ”€ Next Task (export-settings): 14:30:00  ğŸ‘ˆ TIME MATCHED!
â””â”€ Check schedule every second...
```

---

### ğŸ“¤ Ù…Ø±Ø­Ù„Ù‡ 4: Task Ø¨Ù‡ ØµÙ Ø§Ø¶Ø§ÙÙ‡ Ø´ÙˆØ¯

**Ø²Ù…Ø§Ù†: 14:30:00 (Ø¯Ù‚ÛŒÙ‚Ø§Ù‹)**

Beat Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

```python
# Beat internally does:
task = export_settings_to_request_network.delay()  # ÛŒØ§ apply_async()
```

**Ù†ØªÛŒØ¬Ù‡: Redis Queue ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯:**

```
Redis Before:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ celery (queue)   â”‚
â”‚                  â”‚
â”‚ (Ø®Ø§Ù„ÛŒ)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Redis After:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ celery (queue)                        â”‚
â”‚                                      â”‚
â”‚ Message 1:                           â”‚
â”‚ {                                    â”‚
â”‚   "id": "abc123def456",             â”‚
â”‚   "task": "workers.tasks...",       â”‚
â”‚   "args": [],                       â”‚
â”‚   "kwargs": {},                     â”‚
â”‚   "retries": 0,                     â”‚
â”‚   "eta": null                       â”‚
â”‚ }                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Log Ø¯Ø± Beat:**
```
[2025-11-13 14:30:00,000: INFO/MainProcess] Scheduler: Sending due task export-settings-every-minute
[2025-11-13 14:30:00,010: DEBUG/MainProcess] Task sent: export_settings_to_request_network[abc123def456]
```

---

### ğŸ‘· Ù…Ø±Ø­Ù„Ù‡ 5: Worker task Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯

**Ø²Ù…Ø§Ù†: 14:30:00.5 (Ø¨Ù„Ø§ÙØ§ØµÙ„Ù‡ Ø¨Ø¹Ø¯)**

Worker Ù…Ø³Ù„Ø³Ù„ Redis Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

```python
# Worker internally does (in loop):
while True:
    message = redis_queue.pop()  # Ø§Ø² Ø³Ù…Øª Ú†Ù¾ ØµÙ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯
    if message:
        task_id = message['id']
        task_name = message['task']
        
        # Run task
        result = execute_task(task_name, task_id)
        
        # Store result
        redis_backend.set(task_id, result)
```

**Worker Log:**
```
[2025-11-13 14:30:00,020: INFO/MainProcess] Received task: export_settings_to_request_network[abc123def456]
[2025-11-13 14:30:00,030: DEBUG/MainProcess] Task started, id=abc123def456
```

---

### âš™ï¸ Ù…Ø±Ø­Ù„Ù‡ 6: Task Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯

**Ø²Ù…Ø§Ù†: 14:30:00.5 ØªØ§ 14:30:02**

Worker Ú©Ø¯ ØªØ³Ú© Ø±Ø§ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

```python
# ØªØ³Ú© Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯...

# Step 1: Ø§ØªØµØ§Ù„ Ø¨Ù‡ Database
db = next(get_db_sync())  # 200ms

# Step 2: Query Ú©Ø±Ø¯Ù† Settings
settings = db.query(SettingsModel).all()  # 400ms (Ø§Ú¯Ø± 1000 record Ø¨Ø§Ø´Ø¯)

# Step 3: Ø§ÛŒØ¬Ø§Ø¯ JSON
settings_data = [
    {
        "id": "uuid-1",
        "key": "app.title",
        "value": "My App",
        "created_at": "2025-11-13T14:30:00"
    },
    ...
]  # 50ms

# Step 4: Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„
EXPORT_PATH.mkdir(parents=True, exist_ok=True)
export_file = EXPORT_PATH / "settings_latest.json"
with open(export_file, "w") as f:
    json.dump(settings_data, f)  # 100ms

# Step 5: Queue ÙØ§ÛŒÙ„
queue_file = EXPORT_PATH / "settings_queue.json"
if queue_file.exists():
    with open(queue_file, "r") as f:
        queue = json.load(f)
else:
    queue = []

queue.append({
    "timestamp": "2025-11-13T14:30:02",
    "file": "settings_latest.json"
})

with open(queue_file, "w") as f:
    json.dump(queue, f)  # 50ms

# Total: ~800ms
```

**Worker Log:**
```
[2025-11-13 14:30:00,050: DEBUG/solo] Executing task
[2025-11-13 14:30:00,250: INFO/solo] DB connected successfully
[2025-11-13 14:30:00,650: DEBUG/solo] Query completed: 1234 settings
[2025-11-13 14:30:00,750: DEBUG/solo] File written: /exports/settings_latest.json
[2025-11-13 14:30:00,850: INFO/solo] Task completed successfully
```

**ÙØ§ÛŒÙ„ Ø³ÛŒØ³ØªÙ… Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯:**
```
response-network/exports/
â”œâ”€ settings/
â”‚  â”œâ”€ settings_latest.json           ğŸ‘ˆ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯
â”‚  â””â”€ settings_queue.json             ğŸ‘ˆ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯
â”‚
â”œâ”€ users/
â”‚  â””â”€ users_latest.json
â”‚
â””â”€ password_changes/
   â””â”€ password_changes_latest.json
```

---

### âœ… Ù…Ø±Ø­Ù„Ù‡ 7: Ù†ØªÛŒØ¬Ù‡ Ø¨Ù‡ Redis Ø¨Ø±Ú¯Ø±Ø¯Ø¯

**Ø²Ù…Ø§Ù†: 14:30:02**

Worker Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

```python
# Worker internally:
result = {
    "status": "success",
    "count": 1234,
    "file": "/exports/settings_latest.json",
    "exported_at": "2025-11-13T14:30:02"
}

# Store in Redis backend
redis_backend.set(
    f"celery-task-meta-abc123def456",
    json.dumps({
        "status": "SUCCESS",
        "result": result,
        "traceback": None
    }),
    ex=3600  # 1 Ø³Ø§Ø¹Øª
)
```

**Worker Log:**
```
[2025-11-13 14:30:02,100: INFO/solo] Task successful: export_settings_to_request_network[abc123def456]
[2025-11-13 14:30:02,110: DEBUG/solo] Result stored in backend
```

**Redis Backend:**
```
Before:
celery-task-meta-abc123def456: (not exists)

After:
celery-task-meta-abc123def456: {
  "status": "SUCCESS",
  "result": {"status": "success", "count": 1234, ...},
  "traceback": null
}
```

---

### ğŸ”„ Ù…Ø±Ø­Ù„Ù‡ 8: ØªÚ©Ø±Ø§Ø± (Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡)

**Ø²Ù…Ø§Ù†: 14:31:00**

Beat Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù†Ø¸Ø§Ø±Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

```
Beat Scheduler (Running...)
â”œâ”€ Current Time: 14:31:00
â”œâ”€ Next Task (export-settings): 14:31:00  ğŸ‘ˆ TIME MATCHED AGAIN!
â””â”€ Send to Queue again...
```

**Redis Queue:**
```
celery (queue)
â”œâ”€ Message 1 (14:30:00): âœ… COMPLETED
â”œâ”€ Message 2 (14:31:00): ğŸ“¤ QUEUED
â””â”€ Message 3 (14:32:00): â³ WAITING...
```

---

## ğŸŒ Ù†Ù‚Ø´ Request Network

### Ø¯Ø± Request Network
```python
# request-network/workers/celery_app.py

celery_app.conf.beat_schedule = {
    "import-settings-and-passwords-every-minute": {
        "task": "workers.tasks.settings_importer.import_settings_and_passwords",
        "schedule": 60.0,
    },
}
```

**Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡:**

1. âœ… `settings_importer` Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯
2. âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø§Ø² `response-network/exports/` Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯
3. âœ… Database Request Network Ø±Ø§ Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯

```python
# Task Step by Step:

# 1. Ø¨Ø±Ø±Ø³ÛŒ password_changes_queue.json
PASSWORD_CHANGES_PATH = "./exports/password_changes"
queue_file = PASSWORD_CHANGES_PATH / "password_changes_queue.json"

if queue_file.exists():
    # 2. ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†
    with open(queue_file, "r") as f:
        password_changes = json.load(f)  # List of changes
    
    # 3. Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù¾Ø³ÙˆØ±Ø¯
    for change in password_changes:
        user = db.query(User).filter(User.id == change['user_id']).first()
        
        # 4. Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
        user.hashed_password = change['hashed_password']
        user.synced_at = datetime.utcnow()
        db.add(user)
    
    # 5. Commit
    db.commit()
    
    # 6. Ø­Ø°Ù queue
    queue_file.unlink()
```

---

## ğŸ”— ØªØ¹Ø§Ù…Ù„ Unicorn + Celery + Redis

### ÛŒÚ© Ú©Ø§Ø±Ø¨Ø± "Ù¾Ø³ÙˆØ±Ø¯ ØªØºÛŒÛŒØ± Ù…ÛŒØ¯Ù‡Ø¯"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ú©Ø§Ø±Ø¨Ø± (Browser)                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /users/{id}/reset-password
         â”‚ {"new_password": "NewPass123"}
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Unicorn API (:8000)                                          â”‚
â”‚                                                              â”‚
â”‚ @router.post("/{user_id}/reset-password")                  â”‚
â”‚ async def reset_user_password(user_id, request_body, db):   â”‚
â”‚     # 1. Validate
â”‚     user = await db.get(User, user_id)
â”‚                                                              â”‚
â”‚     # 2. Hash password
â”‚     hashed = get_password_hash(request_body["new_password"])â”‚
â”‚                                                              â”‚
â”‚     # 3. Update DB
â”‚     user.hashed_password = hashed
â”‚     await db.commit()
â”‚                                                              â”‚
â”‚     # 4. ğŸ¯ CALL CELERY TASK
â”‚     from workers.tasks.password_sync import \              â”‚
â”‚         sync_password_to_request_network                    â”‚
â”‚     task = sync_password_to_request_network.delay(          â”‚
â”‚         user_id=str(user.id),                               â”‚
â”‚         hashed_password=hashed                              â”‚
â”‚     )                                                        â”‚
â”‚                                                              â”‚
â”‚     return {
â”‚         "success": True,
â”‚         "sync_task_id": task.id
â”‚     }
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Queue message sent to Redis
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Redis (localhost:6380/0)                                     â”‚
â”‚                                                              â”‚
â”‚ celery (queue):                                             â”‚
â”‚ [                                                            â”‚
â”‚   {                                                          â”‚
â”‚     "id": "task_xyz789",                                    â”‚
â”‚     "task": "workers.tasks.password_sync...",              â”‚
â”‚     "args": [],                                             â”‚
â”‚     "kwargs": {                                             â”‚
â”‚       "user_id": "user-uuid-123",                          â”‚
â”‚       "hashed_password": "$2b$12$..."                      â”‚
â”‚     }                                                        â”‚
â”‚   }                                                          â”‚
â”‚ ]                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Worker reads from queue
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Celery Worker (Process)                                      â”‚
â”‚                                                              â”‚
â”‚ def sync_password_to_request_network(user_id, hashed):      â”‚
â”‚                                                              â”‚
â”‚     # 1. Create export directory
â”‚     EXPORT_PATH.mkdir(parents=True, exist_ok=True)          â”‚
â”‚                                                              â”‚
â”‚     # 2. Read queue file
â”‚     queue_file = EXPORT_PATH / "password_changes_queue"     â”‚
â”‚     if queue_file.exists():
â”‚         queue_data = json.load(queue_file)                  â”‚
â”‚     else:
â”‚         queue_data = []
â”‚                                                              â”‚
â”‚     # 3. Add password change
â”‚     queue_data.append({
â”‚         "user_id": user_id,
â”‚         "hashed_password": hashed,
â”‚         "changed_at": now()
â”‚     })
â”‚                                                              â”‚
â”‚     # 4. Write queue file
â”‚     with open(queue_file, "w") as f:                        â”‚
â”‚         json.dump(queue_data, f)
â”‚                                                              â”‚
â”‚     # 5. Return result
â”‚     return {"status": "success"}
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Result stored in Redis backend
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ File System (exports/)                                       â”‚
â”‚                                                              â”‚
â”‚ response-network/exports/                                   â”‚
â”‚ â””â”€ password_changes/                                        â”‚
â”‚    â””â”€ password_changes_queue.json   ğŸ‘ˆ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯             â”‚
â”‚       [                                                      â”‚
â”‚         {                                                    â”‚
â”‚           "user_id": "user-uuid-123",                       â”‚
â”‚           "hashed_password": "$2b$12$...",                 â”‚
â”‚           "changed_at": "2025-11-13T14:30:00"              â”‚
â”‚         }                                                    â”‚
â”‚       ]                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡ Request Network import Ù…ÛŒâ€ŒÚ©Ù†Ø¯
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Request Network Worker (Beat + Worker)                       â”‚
â”‚                                                              â”‚
â”‚ def import_settings_and_passwords():                        â”‚
â”‚     queue_file = "./exports/password_changes_queue.json"    â”‚
â”‚     if queue_file.exists():
â”‚         changes = json.load(queue_file)                     â”‚
â”‚         for change in changes:
â”‚             user = db.get(User, change['user_id'])          â”‚
â”‚             user.hashed_password = change['hashed_password']â”‚
â”‚             user.synced_at = now()
â”‚             db.add(user)
â”‚         db.commit()
â”‚         queue_file.unlink()  # Ø­Ø°Ù Ø¨Ø¹Ø¯ Ø§Ø² Ø¯Ø±Ø¢Ù…Ø¯
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Request Network DB Ø¨Ø±ÙˆØ² Ø´Ø¯
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Request Network Database                                     â”‚
â”‚                                                              â”‚
â”‚ users:                                                       â”‚
â”‚ â”œâ”€ id: user-uuid-123                                       â”‚
â”‚ â”œâ”€ username: john                                          â”‚
â”‚ â”œâ”€ hashed_password: "$2b$12$..." ğŸ‘ˆ SYNCED                â”‚
â”‚ â””â”€ synced_at: 2025-11-13T14:31:00                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Redis Data Structure

### Queue (messages waiting)
```
Key: celery
Type: List (FIFO)
â”œâ”€ [0] = Task message 1
â”œâ”€ [1] = Task message 2
â””â”€ [2] = Task message 3

Commands:
- RPUSH celery <message>  # Add to queue
- LPOP celery             # Get from queue
- LLEN celery             # Queue length
```

### Backend (task results)
```
Key: celery-task-meta-<task_id>
Type: String (JSON)
Value: {
  "status": "SUCCESS" | "FAILURE" | "PENDING",
  "result": {...},
  "traceback": null
}

Commands:
- SET key value EX 3600  # Store result (1 hour)
- GET key                # Retrieve result
- DEL key                # Delete result
```

---

## ğŸ” Monitoring Commands

### 1. Ø¨Ø±Ø±Ø³ÛŒ Queue Length
```bash
redis-cli -p 6380
> LLEN celery
(integer) 5  # 5 tasks in queue

> LPOP celery  # Get first task
"{\"id\": \"abc123...\"}"
```

### 2. Ø¨Ø±Ø±Ø³ÛŒ Active Workers
```bash
celery -A workers.celery_app inspect active

{
  "celery@DESKTOP-ABC123": {
    "active": [
      {
        "id": "abc123def456",
        "name": "workers.tasks.export_settings...",
        "args": [],
        "kwargs": {},
        "time_start": 1234567890.123
      }
    ]
  }
}
```

### 3. Ø¨Ø±Ø±Ø³ÛŒ Task Result
```python
from workers.celery_app import celery_app

# Ø§Ú¯Ø± task_id Ø¯Ø§Ø±ÛŒÙ…:
task = celery_app.AsyncResult("abc123def456")

print(task.state)     # PENDING, STARTED, SUCCESS, FAILURE
print(task.result)    # Ù†ØªÛŒØ¬Ù‡ (Ø§Ú¯Ø± complete Ø§Ø³Øª)
print(task.info)      # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±
```

### 4. Ø¨Ø±Ø±Ø³ÛŒ Beat Schedule
```bash
cd response-network/api
python debug_celery.py

# Output:
# ============================================================
# ğŸ” Celery Configuration Debug
# ============================================================
# 
# 1ï¸âƒ£ Broker & Backend:
#    Broker: redis://localhost:6380/0
#    Backend: redis://localhost:6380/1
# 
# 2ï¸âƒ£ Beat Schedule:
#    âœ… export-settings-every-minute
#       Task: workers.tasks.settings_exporter.export_settings_to_request_network
#       Schedule: 60.0s
```

---

## â¸ï¸ Ù…Ø´Ú©Ù„ Ø¹Ø§Ù…: ØµÙ Ø®Ø§Ù„ÛŒ Ù†ÛŒØ³Øª

```bash
# Ø§Ú¯Ø± ØµÙ Ù¾Ø± Ø§Ø³Øª Ùˆ tasks Ø§Ù†Ø¬Ø§Ù… Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯:

# 1. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Worker ÙØ¹Ø§Ù„ Ø§Ø³Øª:
celery -A workers.celery_app inspect active
# Ø§Ú¯Ø± Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ù†ÛŒØ³Øª â†’ Worker Ø®Ø§Ù…ÙˆØ´ Ø§Ø³Øª!

# 2. Ù¾Ø§Ú© Ú©Ù†ÛŒØ¯ queue:
redis-cli -p 6380
> DEL celery
(integer) 5  # Ø­Ø°Ù Ø´Ø¯ 5 task

# 3. Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯:
python -m celery -A workers.celery_app worker --pool=solo
```

---

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ ÙØ±Ø§ÛŒÙ†Ø¯

```
ğŸ• Beat (Ø³Ø§Ø¹ØªÛŒ)
  â””â”€> Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡ â†’ send task to Redis Queue

ğŸ“¤ Redis Queue (ØµÙ)
  â””â”€> Task message stored as JSON

ğŸ‘· Worker (Ú©Ø§Ø±Ú¯Ø±)
  â””â”€> Get task from queue
      â””â”€> Execute Python function
          â””â”€> Write results to file
              â””â”€> Store result in Redis Backend

âœ… Success!
  â””â”€> Task completed
      â””â”€> File exported
          â””â”€> Other network imported

ğŸ”„ Repeat every 60 seconds...
```

---

## ğŸ“ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ

| ÙØ§ÛŒÙ„ | Ù†Ù‚Ø´ |
|------|------|
| `response-network/api/workers/celery_app.py` | ØªØ¹Ø±ÛŒÙ Celery app + Beat schedule |
| `response-network/api/workers/tasks/settings_exporter.py` | ØªØ³Ú© export settings |
| `response-network/api/workers/tasks/password_sync.py` | ØªØ³Ú© export password changes |
| `response-network/api/start_beat.py` | Ø´Ø±ÙˆØ¹ Beat Scheduler |
| `request-network/workers/celery_app.py` | ØªØ¹Ø±ÛŒÙ Celery worker (Ø¨Ø¯ÙˆÙ† Beat) |
| `request-network/workers/tasks/settings_importer.py` | ØªØ³Ú© import ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ Ù¾Ø³ÙˆØ±Ø¯Ù‡Ø§ |
| `response-network/exports/` | ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ export (Queue files) |

---

## ğŸ—ï¸ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ

```
Response Network:
  Unicorn API (8000)
    â”œâ”€ POST /reset-password â†’ calls celery task
    â””â”€ DB sync

  Celery Beat (Scheduler)
    â”œâ”€ export_settings (Ù‡Ø± 60s)
    â”œâ”€ export_users (Ù‡Ø± 60s)
    â””â”€ export_profile_types (Ù‡Ø± 60s)

  Celery Worker (Executor)
    â”œâ”€ Receives tasks from Queue
    â”œâ”€ Executes and exports files
    â””â”€ Stores results


          â†“ (File Export)

response-network/exports/ (Shared Files)
  â”œâ”€ settings_latest.json
  â”œâ”€ users_queue.json
  â””â”€ password_changes_queue.json


          â†“ (File Import)

Request Network:
  Celery Beat (Scheduler)
    â””â”€ import_settings_and_passwords (Ù‡Ø± 60s)

  Celery Worker (Executor)
    â”œâ”€ Reads exported files
    â”œâ”€ Updates Request Network DB
    â””â”€ Deletes queue files

  Unicorn API (8001)
    â””â”€ Serves synced data
```

---

## âœ¨ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

1. **Beat Ùˆ Worker Ø¨Ø§ÛŒØ¯ Ù‡Ø± Ø¯Ùˆ ÙØ¹Ø§Ù„ Ø¨Ø§Ø´Ù†Ø¯**
   - Beat Ø¨Ø¯ÙˆÙ† Worker = Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ tasks Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
   - Worker Ø¨Ø¯ÙˆÙ† Beat = ÙÙ‚Ø· manual tasks Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯

2. **Redis Ø¨Ø§ÛŒØ¯ Ø´ØºØ§Ù„ Ø¨Ø§Ø´Ø¯**
   - Broker: Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ queue
   - Backend: Ù†ØªØ§ÛŒØ¬

3. **Windows Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ `--pool=solo`**
   - ØªÙ†Ù‡Ø§ ÛŒÚ© Worker process Ø¯Ø± Windows

4. **ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¯Ø± ØµÙ Ø¬Ù…Ø¹ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯**
   - Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡ ÛŒÚ© file Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
   - Request Network Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯

5. **Sync ÛŒÚ©â€ŒØ·Ø±ÙÙ‡ Ø§Ø³Øª**
   - Response â†’ Request Network
   - Ù†Ù‡ Ø¨Ø±Ø¹Ú©Ø³

